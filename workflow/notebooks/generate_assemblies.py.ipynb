{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd5a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79e428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ca6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse Snakemake inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3795f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revised haplotype Fastas\n",
    "occ1_fasta = snakemake.input[0]\n",
    "occ2_fasta = snakemake.input[1]\n",
    "pall1_fasta = snakemake.input[2]\n",
    "pall2_fasta = snakemake.input[3]\n",
    "\n",
    "# TrR v5 to v6 chromosome mapping\n",
    "chromosome_mapping_path = snakemake.input[4]\n",
    "\n",
    "# DF with chromosomes to reverse complement\n",
    "chrs_toRevComp = snakemake.input[5]\n",
    "\n",
    "# Df with scaffold lengths by SG and Hap\n",
    "scaffs_bySG_Hap = snakemake.input[6]\n",
    "\n",
    "# Output\n",
    "haploid_reference = snakemake.output[0]\n",
    "hap1_out = snakemake.output[1]\n",
    "hap2_out = snakemake.output[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd30865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ddad4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters haplotype fasta for scaffold to keep and returns dictionary with record ID a key and sequence as value\n",
    "def get_chromosomal_scaffolds(hap_fasta, chromosomes_df, sg, hap):\n",
    "    \n",
    "    scaffolds_to_keep_df = TrR_v6_chromosomes[(TrR_v6_chromosomes['subgenome'] == sg) & \n",
    "                                           (TrR_v6_chromosomes['haplotype'] == hap)]\n",
    "    scaffolds_to_keep_dict = scaffolds_to_keep_df.set_index('original_scaffold_name')['TrR_v6_chromosome_name'].to_dict()\n",
    "    \n",
    "    chromosome_records = {}\n",
    "    for record in SeqIO.parse(hap_fasta, 'fasta'):\n",
    "        if record.id in scaffolds_to_keep_dict.keys():\n",
    "            new_chromosome_name = scaffolds_to_keep_dict[record.id]\n",
    "            chromosome_records[new_chromosome_name] = record.seq\n",
    "    return(chromosome_records)\n",
    "\n",
    "# Reverse complements sequences to match TrR_v5 assembly (if necessary) and returns new dictionary\n",
    "def reverse_compliment(chromosomal_records, revComp_list):\n",
    "    \n",
    "    all_chromosomal_records_revComp = {}\n",
    "    for chrom, seq in chromosomal_records.items():\n",
    "        if chrom in revComp_list:\n",
    "            all_chromosomal_records_revComp[chrom] = seq.reverse_complement()\n",
    "        else:\n",
    "            all_chromosomal_records_revComp[chrom] = seq\n",
    "    \n",
    "    return(all_chromosomal_records_revComp)\n",
    "\n",
    "# Retrieve plastid and mito sequences\n",
    "def get_organellar_scaffolds(hap_fasta, organelle_name, new_name):\n",
    "    \n",
    "    organellar_record = {}\n",
    "    for record in SeqIO.parse(hap_fasta, 'fasta'):\n",
    "        if record.id == organelle_name:\n",
    "            organellar_record[new_name] = record.seq\n",
    "    return(organellar_record)\n",
    "\n",
    "# Get chromosomes and unplaced scaffolds for subgenome and haplptype\n",
    "# Separate dictionaries for each\n",
    "def get_rename_diploid_scaffs(hap_fasta, scaffs_bySG_Hap_df, sg, hap):\n",
    "    \n",
    "    chroms = scaffs_bySG_Hap_df[(scaffs_bySG_Hap_df['sg'] == sg) & \n",
    "                                (scaffs_bySG_Hap_df['hap'] == hap)]\n",
    "\n",
    "    scaff_names = chroms['scaff'].tolist()\n",
    "    if hap == 'One':\n",
    "        hap_num = 1\n",
    "    else:\n",
    "        hap_num = 2\n",
    "    \n",
    "    allrecs = {}\n",
    "    for record in SeqIO.parse(hap_fasta, 'fasta'):\n",
    "        scaff = record.id.split('__')[0]\n",
    "        if scaff in scaff_names:\n",
    "            new_chromosome_name = f\"{chroms[chroms['scaff'] == scaff]['TrR_v6_chromosome_name'].values[0]}_Hap{hap_num}\"\n",
    "            allrecs[new_chromosome_name] = record.seq\n",
    "        else:\n",
    "            new_scaff_name = f\"{sg.capitalize()}_Hap{hap_num}_{record.id}\"\n",
    "            allrecs[new_scaff_name] = record.seq\n",
    "    \n",
    "    chrom_records = {k:v for k,v in allrecs.items() if k.startswith('Chr')}\n",
    "    unp_records = {k:v for k,v in allrecs.items() if not k.startswith('Chr')}\n",
    "    \n",
    "    return(chrom_records, unp_records)\n",
    "\n",
    "\n",
    "def split_contaminated_sequences(contamination_dict, record_dict):\n",
    "    new_seq_dict = {}  # Dict to store new split sequences\n",
    "    # Iterate through contaminated sequence dictionary\n",
    "    for cont_scaff, conts in contamination_dict.items():\n",
    "        new_scaff_prefix = str.split(cont_scaff, '__')[0]  # Contig name prefix\n",
    "        num_cont = len(conts)  # Number of contaminated stretches\n",
    "        # Iterate through contaminated stretches\n",
    "        for span_num in range(num_cont + 1):\n",
    "            # If we're on the first stretch, slice to start of contamination\n",
    "            if span_num == 0:\n",
    "                first_pos = contamination_dict[cont_scaff][span_num][0]\n",
    "                seq = record_dict[cont_scaff][:first_pos]\n",
    "                new_seq_dict[f\"{new_scaff_prefix}__contSplit{span_num + 1}_length{len(seq)}\"] = seq\n",
    "            # If we're on the last strech, slice from contamination end to end of sequence\n",
    "            elif span_num == num_cont:\n",
    "                last_pos = contamination_dict[cont_scaff][span_num - 1][1]\n",
    "                seq = record_dict[cont_scaff][last_pos:]\n",
    "                new_seq_dict[f\"{new_scaff_prefix}__contSplit{span_num + 1}_length{len(seq)}\"] = seq\n",
    "            # Otherwise, slice from end of previous stretch to start of current one\n",
    "            else:\n",
    "                first_pos = contamination_dict[cont_scaff][span_num - 1][1]\n",
    "                second_pos = contamination_dict[cont_scaff][span_num][0]\n",
    "                seq = record_dict[cont_scaff][first_pos:second_pos]\n",
    "                new_seq_dict[f\"{new_scaff_prefix}__contSplit{span_num + 1}_length{len(seq)}\"] = seq\n",
    "    return(new_seq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e74ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haploid reference assembly\n",
    "\n",
    "## Step 1: Get chromosomal scaffold sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83009b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file with chromosomes to keep and mapping to new names\n",
    "TrR_v6_chromosomes = pd.read_csv(chromosome_mapping_path, delimiter=',')\n",
    "TrR_v6_chromosomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e99227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct records from each haplotype.\n",
    "occ1_chromosomal_records = get_chromosomal_scaffolds(occ1_fasta, TrR_v6_chromosomes, sg = 'Occ', hap = 'One')\n",
    "occ2_chromosomal_records = get_chromosomal_scaffolds(occ2_fasta, TrR_v6_chromosomes, sg = 'Occ', hap = 'Two')\n",
    "pall1_chromosomal_records = get_chromosomal_scaffolds(pall1_fasta, TrR_v6_chromosomes, sg = 'Pall', hap = 'One')\n",
    "pall2_chromosomal_records = get_chromosomal_scaffolds(pall2_fasta, TrR_v6_chromosomes, sg = 'Pall', hap = 'Two')\n",
    "\n",
    "# Merge dictionaries\n",
    "all_chromosomal_records = occ1_chromosomal_records | occ2_chromosomal_records | pall1_chromosomal_records | pall2_chromosomal_records\n",
    "all_chromosomal_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62012745",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Reverse compliment and reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2132fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromosomes that need to be reverse complement to match orientation of Griffiths et al. TrR_v5 genome\n",
    "# Determined by mapping scaffolds against the griffiths genome using minimap2 and looking for a negative correlation in the alignment positions\n",
    "to_reverse_complement = pd.read_csv(chrs_toRevComp, delimiter=',')['TrR_v6_chromosome_name'].tolist()\n",
    "all_chromosomal_records_revComp = reverse_compliment(all_chromosomal_records, revComp_list = to_reverse_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230b77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder chromosomes to match order in CSV file, which matches Griffiths TrR_v5 assembly\n",
    "chromosome_order = TrR_v6_chromosomes['TrR_v6_chromosome_name'].tolist()\n",
    "all_chromosomal_records_revComp_ordered = {chrom : all_chromosomal_records_revComp[chrom] for chrom in chromosome_order if chrom in all_chromosomal_records_revComp}\n",
    "all_chromosomal_records_revComp_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31431bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Add organellar sequences and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c4aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapltoypes and scaffold names for organelles taken from best BLAST hits of entire plastid or COI (for Mitochondria)\n",
    "# Hits were identical between haplotypes for plastid, but Pall 1 had longer assembly for Mitochondria\n",
    "plastid_record = get_organellar_scaffolds(occ1_fasta, 'Scaffold_27__1_contigs__length_126578', 'Plastid')\n",
    "mitochondrial_record = get_organellar_scaffolds(pall1_fasta, 'Scaffold_15__1_contigs__length_370591', 'Mitochondria')\n",
    "\n",
    "# Adde records to end of dictionary\n",
    "haploid_reference_genome = all_chromosomal_records_revComp_ordered | plastid_record | mitochondrial_record\n",
    "haploid_reference_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f8abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fasta\n",
    "with open(haploid_reference, 'w') as fout:\n",
    "    for chrom, seq in haploid_reference_genome.items():\n",
    "        fout.write(f'>{chrom}\\n{str(seq)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a866628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diploid reference assembly\n",
    "\n",
    "## Step 1: Get and rename chromosomes and unplaced scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb22b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with LGs and Scaffs for oth subgenomes and \n",
    "scaffs_bySG_Hap_df = pd.read_csv(scaffs_bySG_Hap)\n",
    "scaffs_bySG_Hap_df = scaffs_bySG_Hap_df.merge(TrR_v6_chromosomes[['LG', 'TrR_v6_chromosome_name']], on = 'LG', how = 'left')\n",
    "scaffs_bySG_Hap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314e1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chromosomes and unplaced scaffolds as separate dictionaries\n",
    "occ1_chrom_recs, occ1_unp_recs = get_rename_diploid_scaffs(occ1_fasta, scaffs_bySG_Hap_df, 'occ', 'One')\n",
    "occ2_chrom_recs, occ2_unp_recs = get_rename_diploid_scaffs(occ2_fasta, scaffs_bySG_Hap_df, 'occ', 'Two')\n",
    "pall1_chrom_recs, pall1_unp_recs = get_rename_diploid_scaffs(pall1_fasta, scaffs_bySG_Hap_df, 'pall', 'One')\n",
    "pall2_chrom_recs, pall2_unp_recs = get_rename_diploid_scaffs(pall2_fasta, scaffs_bySG_Hap_df, 'pall', 'Two')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Combine and reorder chromosomal scaffolds\n",
    "\n",
    "### Haplotype 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16db02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap1_chroms = occ1_chrom_recs | pall1_chrom_recs\n",
    "chromosome_order_hap1 = [f\"{x}_Hap1\" for x in chromosome_order]\n",
    "hap1_chroms_ordered = {chrom : hap1_chroms[chrom] for chrom in chromosome_order_hap1 if chrom in hap1_chroms}\n",
    "hap1_chroms_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Haplotype 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7e7389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap2_chroms = occ2_chrom_recs | pall2_chrom_recs\n",
    "chromosome_order_hap2 = [f\"{x}_Hap2\" for x in chromosome_order]\n",
    "hap2_chroms_ordered = {chrom : hap2_chroms[chrom] for chrom in chromosome_order_hap2 if chrom in hap2_chroms}\n",
    "hap2_chroms_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd853b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap2_revComp = ['Chr08_Occ_Hap2', 'Chr04_Occ_Hap2', 'Chr06_Pall_Hap2', 'Chr04_Pall_Hap2',\n",
    "                'Chr03_Occ_Hap2', 'Chr06_Occ_Hap2', 'Chr07_Occ_Hap2', 'Chr08_Pall_Hap2']\n",
    "hap2_chroms_ordered_revComp = reverse_compliment(hap2_chroms_ordered, revComp_list = hap2_revComp)\n",
    "hap2_chroms_ordered_revComp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Combine, remove contamination, and reorder unplaced scaffolds\n",
    "\n",
    "### Haplotype 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c2558da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap1_unp = occ1_unp_recs | pall1_unp_recs  # Combine\n",
    "\n",
    "# Split contaminated sequences. Based on NCBIs internal analysis \n",
    "hap1_cont_dict = {\n",
    "    'Occ_Hap1_Scaffold_107__1_contigs__length_46767' : [[20586, 20847]],\n",
    "    'Occ_Hap1_Scaffold_40__1_contigs__length_84372' : [[81007, 81768]],\n",
    "    'Occ_Hap1_Scaffold_86__1_contigs__length_53138' : [[18033, 18066], [25511, 25664], [29634, 29670], [38491, 38530], [41489, 42604], [46126, 46162]],\n",
    "    'Pall_Hap1_Scaffold_236__1_contigs__length_26579' : [[3484, 13515], [23428, 25038]],\n",
    "    'Pall_Hap1_Scaffold_36__1_contigs__length_129292' : [[634, 676], [12890, 13489], [19477, 19544], [35165, 35196], [39989, 40023], [41868, 41981], [44213, 44247]],\n",
    "    'Pall_Hap1_Scaffold_37__1_contigs__length_126073' : [[33411, 33448], [45162, 45196], [57377, 57410], [59451, 61291], [62297, 62337]]\n",
    "}\n",
    "hap1_unp_contSplit = split_contaminated_sequences(hap1_cont_dict, hap1_unp)\n",
    "\n",
    "# Remove original contaminated scaffolds\n",
    "for key in hap1_cont_dict.keys():\n",
    "    hap1_unp.pop(key)\n",
    "    \n",
    "# Add split scaffolds\n",
    "hap1_unp_contRemoved = hap1_unp | hap1_unp_contSplit\n",
    "\n",
    "hap1_unp_lengths = {k:len(v) - 1 for k,v in hap1_unp_contRemoved.items()}\n",
    "hap1_unp_lengths_ordered = {k: v for k, v in sorted(hap1_unp_lengths.items(), key=lambda item: item[1], reverse = True)}\n",
    "hap1_unp_ordered = {unp : hap1_unp_contRemoved[unp] for unp in hap1_unp_lengths_ordered.keys() if unp in hap1_unp_contRemoved}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Haplotype 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d4b72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap2_unp = occ2_unp_recs | pall2_unp_recs\n",
    "\n",
    "# Split contaminated sequences. Based on NCBIs internal analysis \n",
    "hap2_cont_dict = {\n",
    "    'Occ_Hap2_Scaffold_113__1_contigs__length_46767' : [[20586, 20847]],\n",
    "    'Occ_Hap2_Scaffold_15__1_contigs__length_264194' : [[130489, 132595], [134710, 134811]],\n",
    "    'Occ_Hap2_Scaffold_16__1_contigs__length_261650' : [[211452, 213333], [213446, 218591], [218700, 218731], [221415, 222701]],\n",
    "    'Occ_Hap2_Scaffold_30__1_contigs__length_122125' : [[88609, 88938]],\n",
    "    'Occ_Hap2_Scaffold_32__1_contigs__length_119019' : [[64053, 64510], [80434, 80468]],\n",
    "    'Occ_Hap2_Scaffold_49__1_contigs__length_84372' : [[81007, 81768]],\n",
    "    'Occ_Hap2_Scaffold_60__1_contigs__length_73558' : [[36749, 36910], [37691, 37722], [44065, 44361], [53875, 53969]],\n",
    "    'Occ_Hap2_Scaffold_95__1_contigs__length_53138' : [[18033, 18066], [25511, 25664], [29634, 29670], [38491, 38530], [41489, 42604], [46126, 46162]],\n",
    "    'Pall_Hap2_Scaffold_35__1_contigs__length_126073' : [[33411, 33448], [45162, 45196], [57377, 57410], [59451, 61291], [62297, 62337]],\n",
    "    'Pall_Hap2_Scaffold_53__1_contigs__length_91932' : [[55949, 56192], [65736, 65817]]\n",
    "}\n",
    "hap2_unp_contSplit = split_contaminated_sequences(hap2_cont_dict, hap2_unp)\n",
    "\n",
    "# Remove original contaminated scaffolds\n",
    "for key in hap2_cont_dict.keys():\n",
    "    hap2_unp.pop(key)\n",
    "    \n",
    "# Add split scaffolds\n",
    "hap2_unp_contRemoved = hap2_unp | hap2_unp_contSplit\n",
    "\n",
    "hap2_unp_lengths = {k:len(v) - 1 for k,v in hap2_unp_contRemoved.items()}\n",
    "hap2_unp_lengths_ordered = {k: v for k, v in sorted(hap2_unp_lengths.items(), key=lambda item: item[1], reverse = True)}\n",
    "hap2_unp_ordered = {unp : hap2_unp_contRemoved[unp] for unp in hap2_unp_lengths_ordered.keys() if unp in hap2_unp_contRemoved}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f362cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Combine and write haplotype fastas\n",
    "\n",
    "### Haplptype 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "033e3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap1 = hap1_chroms_ordered | hap1_unp_ordered\n",
    "with open(hap1_out, 'w') as fout:\n",
    "    for chrom, seq in hap1.items():\n",
    "        fout.write(f'>{chrom}\\n{str(seq)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Haplotype 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45131f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap2 = hap2_chroms_ordered_revComp | hap2_unp_ordered\n",
    "with open(hap2_out, 'w') as fout:\n",
    "    for chrom, seq in hap2.items():\n",
    "        fout.write(f'>{chrom}\\n{str(seq)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
